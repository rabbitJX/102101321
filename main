import requests
import re
import xlwt
import jieba
import wordcloud
import stylecloud
import matplotlib as plt
import pandas as pd


# 获取身份信息，封装请求标头
def GetHeaders():
    # 进入b站，获取Cookie和User-Agent信息（为了防止网站反爬，通常需要进行伪装，一般利用这两个信息就能够爬取网站的基本信息），并封装在headers中
    headers = {
        'Cookie': "buvid3=F1DD24B5-C5E5-94DF-D41A-D3AAF84425CF31615infoc; b_nut=1693973031; i-wanna-go-back=-1; b_ut=7; _uuid=CEC9B861-E2BC-7BCC-A956-D2A8B382FDBC31893infoc; buvid4=35252A41-1298-7C0E-3449-93D27C95FCF432494-023090612-X83v1qigvaVZfatF2QXk2A%3D%3D; header_theme_version=CLOSE; CURRENT_FNVAL=4048; bp_video_offset_399417324=253625691508648509; rpdid=|(u)luk)))~~0J'uYmJm)lR)R; bp_video_offset_1110022060=839960934424248355; SESSDATA=76b8da2d%2C1710001324%2Cb1e5a%2A91CjARDZ0xIKhi1MCFUmBMKNyuP3hpQKguMCR7m9F_4Uc3hqKkWdIgNPvJUeMyYxwjpXsSVnBURjZHLURUcnA5ckZqa0xELUp2eGlDZTFyX1dqVVRTRGVhZEVuV3habFhzQzU5NVd2WWdXNHBhM3oyRUZzZ0xEYURyRFluUUpHT3F1TGRTU2dGT293IIEC; bili_jct=1cf74cb1bfee9edc7fdc44ae30c5c727; DedeUserID=1110022060; DedeUserID__ckMd5=f2a6d1506883cf9a; sid=7nhlmx8f; PVID=3; fingerprint=b8df6d1fb663e0146e6113bd51d7b3d8; buvid_fp_plain=undefined; buvid_fp=b8df6d1fb663e0146e6113bd51d7b3d8; b_lsid=4AD9FB92_18A91CBCB72; innersign=0; home_feed_column=4; browser_resolution=409-998",
        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/116.0.0.0 Safari/537.36 Edg/116.0.1938.76',
    }
    # 返回headers
    return headers


# 访问并爬取视频页面信息接口
def RequestUrl(page, title):
    # 获得视频页面信息接口
    # 由于300个视频一个页面装不下，需要多个页面，故设置page变量满足翻页需求，能够获取不同页面的所有视频信息
    url = 'https://api.bilibili.com/x/web-interface/wbi/search/type?__refresh__=true&_extra=&context=&page=' + str(page) + '&page_size=42&from_source=&from_spmid=333.337&platform=pc&highlight=1&single_column=0&keyword=' + title + '&qv_id=fBoGUUYz7hKF97P6ugHWkzTz7QdmwgSg&ad_resource=5654&source_tag=3&gaia_vtoken=&category_id=&search_type=video'
    # 请求并爬取
    response = requests.get(url=url, headers=GetHeaders())
    # 返回爬取内容
    return response


# 爬取bvid
def GetBvid(response):
    # 利用正则表达式，获得视频bvid号，返回的是一个列表
    bvid = re.findall('"bvid":"(.*?)","title"', response.text)
    return bvid


# 获取cid
def GetCid(bvid):
    # cid获取接口
    cid_url = "https://api.bilibili.com/x/player/pagelist?bvid=" + bvid + "&amp;jsonp=jsonp"
    res = requests.get(url=cid_url, headers=GetHeaders())
    res.encoding = 'utf-8'
    # print(res.text)
    # 利用正则表达式，获得cid号，并转换成字符串
    cid = ''.join(re.findall('"cid":(.*?),"page"', res.text))
    return cid


#获取视频弹幕
def GetDanmu(cid):
    # 获取弹幕接口，一个cid对应一个视频弹幕
    danmu_url = "https://api.bilibili.com/x/v1/dm/list.so?oid=" + str(cid)
    # print(danmu_url)
    content = requests.get(url=danmu_url, headers=GetHeaders())
    content.encoding = 'utf-8'
    # 利用正则表达式，清洗无关内容，获取弹幕内容
    danmu = re.findall('<d p=".*?">(.*?)</d>', content.text)
    # print(danmu)
    return danmu


# 获取数量排名前20的弹幕
def Top20(danmu_all):
    # danmu_all是一个字典类型的数据，存放的内容格式为{('弹幕': '数量')}
    # 依据danmu_all的values值进行降序排序
    danmu_all = sorted(danmu_all.items(), key=lambda danmu_all: danmu_all[1], reverse=True)
    # print(danmu_all)

    # 输出数量排名前20个的弹幕，并保存
    for i, cnt in zip(danmu_all, range(20)):
        print(i[0])

    # print(danmu_top20)
    # 返回排完序后的弹幕内容
    return danmu_all


# 将弹幕内容及其数量写入Excel表格中
def Write_to_Excel(danmu_all):
    # 建立一个新的Excel表格
    book = xlwt.Workbook(encoding='utf-8', style_compression=0)
    # 命名该表格
    sheet = book.add_sheet('DanMu_Analyze', cell_overwrite_ok=True)
    # 定义表格每列的标题
    col = ('Content of Danmu', 'amount')
    # 先将标题写入表格，格式为2*n的表格
    for i in range(2):
        sheet.write(0, i, col[i])
    # 将数据依次写入表格中，本表格只设定填入数量排名前100的弹幕
    for item, row in zip(danmu_all, range(1, 100)):
        for column in range(2):
            sheet.write(row, column, item[column])
    #path = input("Please enter the path that you want:")
    # 设定路径并保存表格
    path = 'C:/Users/JiaXin/Desktop/exl.xls'
    book.save(path)
    Vision()


# 生成直方图
def Vision():
    # 读取 Excel 文件
    data = pd.read_excel('danmu.xlsx')
    # 提取弹幕和数量列
    danmu = data['Content of Danmu']
    quantity = data['amount']
    # 设置中文字体
    plt.rcParams['font.family'] = ['SimHei']
    # 绘制直方图
    plt.bar(danmu, quantity)
    # 设置图形标题和x/y轴标签
    plt.title('弹幕数量分布')
    plt.xlabel('Content of Danmu')
    plt.ylabel('amount')
    # 自动调整x轴标签的旋转角度，使其更易读
    plt.xticks(rotation=90)
    # 保存为图片
    plt.savefig('Vision of Danmu.png')


# 制作词云图
def WorldCloud():
    f = open('content.txt', encoding='utf-8')
    txt = f.read()
    # 使用jieba分词模块，提取出关键字
    string = ' '.join(jieba.lcut(txt))
    # 设置基本参数，导入模板图片
    wc = wordcloud.WordCloud(
        width=700,
        height=700,
        background_color='white',
        scale=20,
        font_path='msyh.ttc',
        #mask='sea.png'
    )
    wc.generate(txt)
    wc.to_file('content.png')


# 导入需要的库stylecloud
def StyleCloud():
    with open('danmu.txt', 'r', encoding='utf-8') as fp:
        text = fp.read()

    a = ''.join(jieba.lcut(text))

    stylecloud.gen_stylecloud(
        #file_path='danmu.txt',
        text = a,
        icon_name='fas fa-fish',
        palette='cmocean.diverging.Balance_20',
        font_path="msyh.ttc",
        background_color='white',
        output_name='xjxcloud.jpg',
        gradient='horizontal',
        invert_mask=False,
        size=2048,
        max_words=300
        )




title = '日本核污染水排海'
danmu_all = dict()
cnt, pages, numbers = 0, 9, 300

for page in range(1, pages):
    response = RequestUrl(page, title)
    # response.encoding = 'utf-8'
    # print(response.text)

    bvid = GetBvid(response)
    #print(bvid)

    for bv in bvid:
        cnt += 1
        if cnt > numbers:
            break
        cid = GetCid(bv)
        #print(cid)

        danmu = GetDanmu(cid)
        for dm in danmu:
            if dm not in danmu_all:
                danmu_all[dm] = 1
            else:
                danmu_all[dm] += 1

for i in danmu_all.keys():
    with open('content.txt', 'a', encoding='utf-8') as fp:
        fp.write(i + '\n')

danmu_all = Top20(danmu_all)
Write_to_Excel(danmu_all)
StyleCloud()

